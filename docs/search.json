[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "READING:\n\n\nBEADING\n\nHIKING:\nI love hiking\n\nLiving in Southern California, I leverage exploring the outdoors. \n\nCOMMUNITY: club involvments"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bernice Abanda",
    "section": "",
    "text": "Bernice Abanda is a current senior majoring in Economics and Data Science. When not in class and or innovating on data platforms, Bernice enjoys spending time watching commentary videos and documentaries, editing software, and hiking."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Bernice Abanda",
    "section": "Education",
    "text": "Education\nScripps College | Claremont, CA | August 2021 - May 2025"
  },
  {
    "objectID": "shakespearse.html",
    "href": "shakespearse.html",
    "title": "Shakespeare",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\nlibrary(tidytext)\nlibrary(devtools)\nlibrary(ggwordcloud)\nlibrary(png)\nlibrary(svglite)\n\n\nhamlet &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-09-17/hamlet.csv')\n\nRows: 4217 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): act, scene, character, dialogue\ndbl (1): line_number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmacbeth &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-09-17/macbeth.csv')\n\nRows: 2553 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): act, scene, character, dialogue\ndbl (1): line_number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nromeo_juliet &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-09-17/romeo_juliet.csv')\n\nRows: 3282 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): act, scene, character, dialogue\ndbl (1): line_number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nview(hamlet)\n\n\nview(macbeth)\n\n\nview(romeo_juliet)\n\n\n#wordcloud2(demoFreq, size = 0.7, shape = 'star')\n\n\nromeo_juliet &lt;- romeo_juliet |&gt;  \n  filter(character %in% c(\"Romeo\",\"Juliet\")) \n\n\n# Create a custom list of words to exclude\ncustom_stop_words &lt;- c(\"thou\", \"thy\", \"thee\", \"thine\", \"art\", \"hast\", \"dost\", \"ere\", \"o\",\"hath\")\n\nword_counts &lt;- romeo_juliet %&gt;%\n  unnest_tokens(word, dialogue) %&gt;%\n  anti_join(stop_words) %&gt;%  # Remove common stop words\n  filter(!str_detect(word, \"^[0-9]+$\")) %&gt;%  # Remove numbers\n  filter(!word %in% custom_stop_words) %&gt;%  # Remove custom words\n  count(character, word, sort = TRUE)\n\nJoining with `by = join_by(word)`\n\n\n\ncombined_word_counts &lt;- word_counts %&gt;%\n  group_by(word, character) %&gt;%\n  summarise(n = sum(n)) %&gt;%\n  arrange(desc(n)) \n\n`summarise()` has grouped output by 'word'. You can override using the\n`.groups` argument.\n\ncombined_word_counts\n\n# A tibble: 1,973 × 3\n# Groups:   word [1,662]\n   word   character     n\n   &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt;\n 1 love   Romeo        46\n 2 romeo  Juliet       36\n 3 love   Juliet       32\n 4 night  Juliet       30\n 5 death  Romeo        21\n 6 nurse  Juliet       20\n 7 sweet  Juliet       16\n 8 fair   Romeo        15\n 9 juliet Romeo        15\n10 mine   Romeo        14\n# ℹ 1,963 more rows\n\n\n\njuliet &lt;- combined_word_counts |&gt; \n  filter(character == \"Juliet\")\n\n\njuliet  |&gt; \n  ggplot(aes(label = word, size = n, color = n)) +\n  ggwordcloud::geom_text_wordcloud()\n\nWarning in wordcloud_boxes(data_points = points_valid_first, boxes = boxes, :\nSome words could not fit on page. They have been placed at their original\npositions.\n\n\n\n\n\n\n\n\n\n\nromeo &lt;- combined_word_counts |&gt; \n  filter(character == \"Romeo\")\n\n\nset.seed(42)\np1_ro &lt;- ggplot(\n  romeo,\n  aes(\n    label = word, size = n,color = n\n  )\n) +\n  geom_text_wordcloud_area() +\n  scale_size_area(max_size = 20) +\n  theme_minimal() +\n  scale_color_gradient(low = \"#FF69B4\", high = \"#C41E3A\")\np1_ro\n\nWarning in wordcloud_boxes(data_points = points_valid_first, boxes = boxes, :\nSome words could not fit on page. They have been placed at their original\npositions."
  },
  {
    "objectID": "projects.html#editor-visual",
    "href": "projects.html#editor-visual",
    "title": "Bernice Abanda",
    "section": "editor: visual",
    "text": "editor: visual"
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "project3_simulation",
    "section": "",
    "text": "Description of Plan\nThis project simulates a college room draw process to estimate the probability of getting a room in the Fancy Dorm. Each student in a given class year is randomly assigned a number to determine their priority in selecting a room, with lower numbers picking first. For this simulation, I’ll focus on sophomores assigned numbers between 401 and 800. I will simulate multiple rounds of the room draw process, where the probability of getting a Fancy Dorm spot depends on their draw number and dorm availability.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(ggplot2)\n\n# Function to simulate room draw for one iteration\nsimulate_draw &lt;- function() {\n  \n  sophomores &lt;- data.frame(student_id = 1:400, \n                           draw_number = sample(401:800, 400))\n  # Check who gets into Fancy Dorm \n  fancy_dorm_cutoff &lt;- 450  \n  sophomores &lt;- sophomores %&gt;%\n    mutate(in_fancy_dorm = ifelse(draw_number &lt;= fancy_dorm_cutoff, TRUE, FALSE))\n  mean(sophomores$in_fancy_dorm)  # Return proportion of those who get in\n}\n\n# Run simulation over many iterations\nresults &lt;- map_dbl(1:1000, ~ simulate_draw())  # 1000 simulations\n\n# Plot results\nggplot(data.frame(probability = results), aes(x = probability)) +\n  geom_histogram(binwidth = 0.01) +\n  labs(title = \"Probability of Getting into Fancy Dorm\", x = \"Probability\", y = \"Frequency\")\n\n\n\n\n\n\n\n\nInterpretation of Plot: The plotillustrates the probability distribution of securing a spot in Fancy Dorm over multiple room draw simulations. It shows the likelihood of different outcomes, offering insight into how lucky or unlucky a student would need to be to get a preferred room. This visual can help students understand the chances of getting into Fancy Dorm based on their draw number.\nEnd-of-Project Summary: This simulation modeled the room draw process to estimate the probability of securing a room in Fancy Dorm. By running 1,000 iterations, we observed the distribution of probabilities, which can inform students about their chances. This method demonstrates how random allocation in room selection impacts student outcomes and highlights the importance of draw number in college housing lotteries."
  },
  {
    "objectID": "Netflix_DescriptionofData.html",
    "href": "Netflix_DescriptionofData.html",
    "title": "Netflix_Data_Analysis",
    "section": "",
    "text": "This bar plot shows the number of Netflix titles containing the words “Love” and “Adventure.” We see that there are more titles containing the word “Love” than “Adventure,” indicating a possible trend in romantic or relationship-based content on Netflix. This gives us insights into popular themes among Netflix titles.\n\n\n\nThis histogram illustrates the distribution of Netflix title description lengths. The majority of descriptions are between 100 and 200 characters long, with a few longer descriptions. This suggests that Netflix descriptions tend to be concise, likely focusing on providing just enough information to capture viewers’ attention without overwhelming them."
  },
  {
    "objectID": "Netflix_DescriptionofData.html#netflix-data-analysis",
    "href": "Netflix_DescriptionofData.html#netflix-data-analysis",
    "title": "Netflix_Data_Analysis",
    "section": "",
    "text": "This bar plot shows the number of Netflix titles containing the words “Love” and “Adventure.” We see that there are more titles containing the word “Love” than “Adventure,” indicating a possible trend in romantic or relationship-based content on Netflix. This gives us insights into popular themes among Netflix titles.\n\n\n\nThis histogram illustrates the distribution of Netflix title description lengths. The majority of descriptions are between 100 and 200 characters long, with a few longer descriptions. This suggests that Netflix descriptions tend to be concise, likely focusing on providing just enough information to capture viewers’ attention without overwhelming them."
  },
  {
    "objectID": "netflix_dataanalysis1.html",
    "href": "netflix_dataanalysis1.html",
    "title": "netflix_dataanalysis1",
    "section": "",
    "text": "```{r}\n}library(readr) netflix_titles &lt;- readr::read_csv(’https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv’)) # Check the structure of the dataset str(netflix_titles)\n```"
  },
  {
    "objectID": "netflix_dataanalysis1.html#section",
    "href": "netflix_dataanalysis1.html#section",
    "title": "netflix_dataanalysis1",
    "section": "",
    "text": "```{r}\n}library(readr) netflix_titles &lt;- readr::read_csv(’https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv’)) # Check the structure of the dataset str(netflix_titles)\n```"
  },
  {
    "objectID": "netflix_dataanalysis1.html#str_-functions-regular-expressions",
    "href": "netflix_dataanalysis1.html#str_-functions-regular-expressions",
    "title": "netflix_dataanalysis1",
    "section": "3 str_*() functions + regular expressions",
    "text": "3 str_*() functions + regular expressions\nlibrary(stringr)"
  },
  {
    "objectID": "netflix_titles.html",
    "href": "netflix_titles.html",
    "title": "netflix_titles",
    "section": "",
    "text": "library(tidytuesdayR)\nlibrary(readr)\n\n# Load the dataset\nnetflix_titles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')\n\nRows: 7787 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (11): show_id, type, title, director, cast, country, date_added, rating,...\ndbl  (1): release_year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nObserve Structure of Data Set\n\nstr(netflix_titles)  # To see the structure of the dataset\n\nspc_tbl_ [7,787 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ show_id     : chr [1:7787] \"s1\" \"s2\" \"s3\" \"s4\" ...\n $ type        : chr [1:7787] \"TV Show\" \"Movie\" \"Movie\" \"Movie\" ...\n $ title       : chr [1:7787] \"3%\" \"7:19\" \"23:59\" \"9\" ...\n $ director    : chr [1:7787] NA \"Jorge Michel Grau\" \"Gilbert Chan\" \"Shane Acker\" ...\n $ cast        : chr [1:7787] \"João Miguel, Bianca Comparato, Michel Gomes, Rodolfo Valente, Vaneza Oliveira, Rafael Lozano, Viviane Porto, Me\"| __truncated__ \"Demián Bichir, Héctor Bonilla, Oscar Serrano, Azalia Ortiz, Octavio Michel, Carmen Beato\" \"Tedd Chan, Stella Chung, Henley Hii, Lawrence Koh, Tommy Kuan, Josh Lai, Mark Lee, Susan Leong, Benjamin Lim\" \"Elijah Wood, John C. Reilly, Jennifer Connelly, Christopher Plummer, Crispin Glover, Martin Landau, Fred Tatasc\"| __truncated__ ...\n $ country     : chr [1:7787] \"Brazil\" \"Mexico\" \"Singapore\" \"United States\" ...\n $ date_added  : chr [1:7787] \"August 14, 2020\" \"December 23, 2016\" \"December 20, 2018\" \"November 16, 2017\" ...\n $ release_year: num [1:7787] 2020 2016 2011 2009 2008 ...\n $ rating      : chr [1:7787] \"TV-MA\" \"TV-MA\" \"R\" \"PG-13\" ...\n $ duration    : chr [1:7787] \"4 Seasons\" \"93 min\" \"78 min\" \"80 min\" ...\n $ listed_in   : chr [1:7787] \"International TV Shows, TV Dramas, TV Sci-Fi & Fantasy\" \"Dramas, International Movies\" \"Horror Movies, International Movies\" \"Action & Adventure, Independent Movies, Sci-Fi & Fantasy\" ...\n $ description : chr [1:7787] \"In a future where the elite inhabit an island paradise far from the crowded slums, you get one chance to join t\"| __truncated__ \"After a devastating earthquake hits Mexico City, trapped survivors from all walks of life wait to be rescued wh\"| __truncated__ \"When an army recruit is found dead, his fellow soldiers are forced to confront a terrifying secret that's haunt\"| __truncated__ \"In a postapocalyptic world, rag-doll robots hide in fear from dangerous machines out to exterminate them, until\"| __truncated__ ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   show_id = col_character(),\n  ..   type = col_character(),\n  ..   title = col_character(),\n  ..   director = col_character(),\n  ..   cast = col_character(),\n  ..   country = col_character(),\n  ..   date_added = col_character(),\n  ..   release_year = col_double(),\n  ..   rating = col_character(),\n  ..   duration = col_character(),\n  ..   listed_in = col_character(),\n  ..   description = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nhead(netflix_titles)  # To view the first few rows of the dataset\n\n# A tibble: 6 × 12\n  show_id type    title director    cast  country date_added release_year rating\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt; \n1 s1      TV Show 3%    &lt;NA&gt;        João… Brazil  August 14…         2020 TV-MA \n2 s2      Movie   7:19  Jorge Mich… Demi… Mexico  December …         2016 TV-MA \n3 s3      Movie   23:59 Gilbert Ch… Tedd… Singap… December …         2011 R     \n4 s4      Movie   9     Shane Acker Elij… United… November …         2009 PG-13 \n5 s5      Movie   21    Robert Luk… Jim … United… January 1…         2008 PG-13 \n6 s6      TV Show 46    Serdar Akar Erda… Turkey  July 1, 2…         2016 TV-MA \n# ℹ 3 more variables: duration &lt;chr&gt;, listed_in &lt;chr&gt;, description &lt;chr&gt;\n\n\nDetecting Titles in Dataset\n\nsummary(netflix_titles)\n\n   show_id              type              title             director        \n Length:7787        Length:7787        Length:7787        Length:7787       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n     cast             country           date_added         release_year \n Length:7787        Length:7787        Length:7787        Min.   :1925  \n Class :character   Class :character   Class :character   1st Qu.:2013  \n Mode  :character   Mode  :character   Mode  :character   Median :2017  \n                                                          Mean   :2014  \n                                                          3rd Qu.:2018  \n                                                          Max.   :2021  \n    rating            duration          listed_in         description       \n Length:7787        Length:7787        Length:7787        Length:7787       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n\nlibrary(stringr)\n\n# Find titles containing the word \"Love\"\nnetflix_titles$has_love &lt;- str_detect(netflix_titles$title, \"Love\")\nsum(netflix_titles$has_love)  # Count number of titles with \"Love\"\n\n[1] 168\n\n# Find titles containing the word \"War\"\nnetflix_titles$has_war &lt;- str_detect(netflix_titles$title, \"War\")\nsum(netflix_titles$has_war)  # Count number of titles with \"War\"\n\n[1] 62\n\n# Find  titles containing the word \"Adventure\"\nnetflix_titles$has_adventure &lt;- str_detect(netflix_titles$title, \"Adventure\")\nsum(netflix_titles$has_adventure)  # Count number of titles with \"Adventure\"\n\n[1] 34\n\n\nCounting Genres\n\nnetflix_titles$genres &lt;- str_extract(netflix_titles$listed_in, \"(Drama|Comedy|Horror)\")\ntable(netflix_titles$genres)\n\n\nComedy  Drama Horror \n   381   2810    352 \n\n\nAnalyze Description Length\n\nnetflix_titles$desc_length &lt;- str_length(netflix_titles$description)\nsummary(netflix_titles$desc_length)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   61.0   140.0   146.0   143.1   149.0   248.0 \n\n\nBar Plot\n\nlibrary(ggplot2)\n\n# Create a data frame of word counts\nword_counts &lt;- data.frame(\n  Category = c(\"Love\", \"War\", \"Adventure\"),\n  Count = c(sum(netflix_titles$has_love), sum(netflix_titles$has_war), sum(netflix_titles$has_adventure))\n)\n\n# Plot the data\nggplot(word_counts, aes(x = Category, y = Count, fill = Category)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Count of Titles Containing Specific Words\", x = \"Category\", y = \"Count\")\n\n\n\n\n\n\n\n\n\nDescription for Bar Plot:\nThis bar plot shows the number of Netflix titles containing the words “Love” and “Adventure.” We see that there are more titles containing the word “Love” than “Adventure,” indicating a possible trend in romantic or relationship-based content on Netflix. This gives us insights into popular themes among Netflix titles.\nHistogram\n\nggplot(netflix_titles, aes(x = desc_length)) +\n  geom_histogram(binwidth = 10, fill = \"blue\", color = \"white\") +\n  labs(title = \"Distribution of Description Lengths\", x = \"Description Length\", y = \"Frequency\")\n\n\n\n\n\n\n\n\n\n\nDescription for Histogram:\nThis histogram illustrates the distribution of Netflix title description lengths. The majority of descriptions are between 100 and 200 characters long, with a few longer descriptions. This suggests that Netflix descriptions tend to be concise, likely focusing on providing just enough information to capture viewers’ attention without overwhelming them."
  },
  {
    "objectID": "WAC_Visualization.html",
    "href": "WAC_Visualization.html",
    "title": "WAC Data Visualozation",
    "section": "",
    "text": "library(tidyr)\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(dbplyr)\n\n\nAttaching package: 'dbplyr'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    ident, sql\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = 'scidb.smith.edu',\n  user = \"waiuser\", password = 'smith_waiDB',\n  dbname = 'wai'\n)\n\nMeasurements &lt;- tbl(con_wai, 'Measurements')\nPI_Info &lt;- tbl(con_wai, 'PI_Info')\nSubjects &lt;- tbl(con_wai, 'Subjects')\n\n# collect(Measurements)\n#Duplicate figure 1 from Voss 2020\nsql_ident &lt;- \"\n  SELECT Identifier, COUNT(Identifier)\n  FROM Measurements\n  GROUP BY Identifier\n\"\n\n\"SELECT DISTINCT Identifier\n  FROM Measurements\"\n\n[1] \"SELECT DISTINCT Identifier\\n  FROM Measurements\"\n\nident &lt;- as_tibble(dbGetQuery(con_wai, sql_ident))\nident$`Identifier`[31:43]\n\n [1] \"Pitaro_2016\"   \"Rosowski_2012\" \"Sanford_2009\"  \"Sanford_2014\" \n [5] \"Shahnaz_2006\"  \"Shaver_2013\"   \"Sliwa_2020\"    \"Sun_2016\"     \n [9] \"Sun_2023\"      \"Voss_1994\"     \"Voss_2010\"     \"Voss_2016\"    \n[13] \"Werner_2010\""
  },
  {
    "objectID": "WAC_Visualization.html#plot-by-group-e.g.-sex",
    "href": "WAC_Visualization.html#plot-by-group-e.g.-sex",
    "title": "WAC Data Visualozation",
    "section": "Plot by group (e.g., Sex)",
    "text": "Plot by group (e.g., Sex)\n\nlibrary(ggplot2)\nggplot(plot_data2, aes(x = freq, y = mean_absorbance, color = sex)) +\ngeom_line() +\nlabs(\n  title = \"(Mean Absorbance by Ethnicity)\",\n    x = \"Frequency (Hz)\",\n   y = \"Mean Absorbance\",\n  color = \"sex\")"
  },
  {
    "objectID": "ds2-hw7-bernice2023/ds2-hw7-webscrape.html",
    "href": "ds2-hw7-bernice2023/ds2-hw7-webscrape.html",
    "title": "DS002R - HW 7 - Web scraping",
    "section": "",
    "text": "Q1 SongKick\nScrape the list of top 200 artists from https://www.songkick.com/leaderboards/popular_artists. (SongKick is a website designed to track artists and their live tour dates.)\nDon’t forget to change #| eval: false to #| eval: true so that your code will run (after you’ve filled in the blanks).\n\nRead the html page\n\n\nlibrary(rvest)\n#| eval: false\npage &lt;- read_html(\"/Users/berniceabanda/git/songkick_page.html\")\n\n\nScrape the artists\n\n\nartists &lt;- page |&gt;\n  html_elements(\".name strong\") |&gt;\n  html_text()\n\n\nScrape the number of fans\n\n\nlibrary(stringr)\nlibrary(rvest)\nlibrary(httr)\n\nfans &lt;- page |&gt;  \n  html_elements(\".leaderboard-list-item .count\") |&gt;  \n  html_text() |&gt;  \n  str_extract(\"\\\\d+\") |&gt;  \n  str_remove_all(\",\") |&gt;  \n  as.numeric()  \n\n\nScrape the number of concerts\n\n\nconcerts &lt;- page |&gt;  \n  html_elements(\".leaderboard-list-item .count + .count\") |&gt;  \n  html_text() |&gt;  \n  str_extract(\"\\\\d+\") |&gt;  \n  as.numeric()  \n\n\nPut it all in a data frame\n\n\nsongkick_top_200 &lt;- tibble(  \n  artist = artists,  \n  fan = fans,  \n  concert = concerts  \n)  \n\n\nAdd the rank associated with each artist. Print the first few row of the tibble.\n\n\nsongkick_top_200 &lt;- songkick_top_200 |&gt;  \n  mutate(rank = 0:nrow(songkick_top_200)) |&gt;  \n  relocate(rank) \n\n\n\nQ2 WNBA\nConsider the data on WNBA standings for the last 15 years provided at https://www.wnba.com/standings.\n\nGo to the WNBA standings website and scrape the standings table. (Note that the html_table() function returns a list of tables, even though there is only one table. To get the first table (one out of one), you’ll need html_table() |&gt; pluck(1) whose output should be a tibble.) Print the first few row of the tibble.\n\n\nlibrary(rvest)  \nlibrary(tibble)  \nlibrary(purrr)  \nlibrary(ggplot2) \nwnba_page &lt;- read_html(\"https://www.wnba.com/standings\")\nwnba_standings &lt;- wnba_page |&gt;\n  html_table() |&gt;\n  pluck(1)\nhead(wnba_standings)\n\n# A tibble: 6 × 10\n  TEAM          W     L   PCT GB    CONF  HOME  ROAD  STREAK `L-10`\n  &lt;chr&gt;     &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; \n1 1NYLClose    32     8 0.8   --    16-4  16-4  16-4  L1     7-3   \n2 2MINClose    30    10 0.75  2     14-6  16-4  14-6  L1     8-2   \n3 3CONClose    28    12 0.7   4     14-6  14-6  14-6  W1     6-4   \n4 4LVAClose    27    13 0.675 5     12-8  13-7  14-6  W5     9-1   \n5 5SEAClose    25    15 0.625 7     13-7  14-6  11-9  W1     6-4   \n6 6INDClose    20    20 0.5   12    11-9  12-8  8-12  L1     6-4   \n\nprint(wnba_standings) \n\n# A tibble: 12 × 10\n   TEAM            W     L   PCT GB    CONF  HOME  ROAD  STREAK `L-10`\n   &lt;chr&gt;       &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; \n 1 1NYLClose      32     8 0.8   --    16-4  16-4  16-4  L1     7-3   \n 2 2MINClose      30    10 0.75  2     14-6  16-4  14-6  L1     8-2   \n 3 3CONClose      28    12 0.7   4     14-6  14-6  14-6  W1     6-4   \n 4 4LVAClose      27    13 0.675 5     12-8  13-7  14-6  W5     9-1   \n 5 5SEAClose      25    15 0.625 7     13-7  14-6  11-9  W1     6-4   \n 6 6INDClose      20    20 0.5   12    11-9  12-8  8-12  L1     6-4   \n 7 7PHOClose      19    21 0.475 13    10-10 10-10 9-11  L1     3-7   \n 8 8ATLClose      15    25 0.375 17    7-13  8-12  7-13  W3     5-5   \n 9 9WASCircle     14    26 0.35  18    7-13  5-15  9-11  W1     6-4   \n10 10CHICircle    13    27 0.325 19    5-15  6-14  7-13  L5     2-8   \n11 11DALCircle     9    31 0.225 23    6-14  7-13  2-18  L9     1-9   \n12 12LASCircle     8    32 0.2   24    5-15  5-15  3-17  W1     2-8   \n\n\n\nClean up the TEAM variable so that it has two columns: first is the final rank, second is the three digit team code for each team. Print the first few row of the tibble.\n\n\nwnba_standings &lt;- wnba_standings |&gt;\n  separate(TEAM, into = c(\"rank\", \"team\"), sep = \" \", extra = \"merge\")\nhead(wnba_standings)\n\n# A tibble: 6 × 11\n  rank      team      W     L   PCT GB    CONF  HOME  ROAD  STREAK `L-10`\n  &lt;chr&gt;     &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; \n1 1NYLClose &lt;NA&gt;     32     8 0.8   --    16-4  16-4  16-4  L1     7-3   \n2 2MINClose &lt;NA&gt;     30    10 0.75  2     14-6  16-4  14-6  L1     8-2   \n3 3CONClose &lt;NA&gt;     28    12 0.7   4     14-6  14-6  14-6  W1     6-4   \n4 4LVAClose &lt;NA&gt;     27    13 0.675 5     12-8  13-7  14-6  W5     9-1   \n5 5SEAClose &lt;NA&gt;     25    15 0.625 7     13-7  14-6  11-9  W1     6-4   \n6 6INDClose &lt;NA&gt;     20    20 0.5   12    11-9  12-8  8-12  L1     6-4   \n\n\n\nDo the same thing for the 2014 season. Print the first few row of the tibble.\n\n\n# Filter for 2014 season data\n\nstandings_2014 &lt;- read_html(\"https://www.wnba.com/standings/?season=2014\") |&gt;  \n  html_table() |&gt;  \n  pluck(1)  \n\n#Clean up the variables\nstandings_2014 &lt;- standings_2014 |&gt;  \n  mutate(  \n   rank = str_extract(TEAM, \"^\\\\d+\"),  \n   team = str_remove(TEAM, \"^\\\\d+\\\\s\"),  \n   TEAM = NULL  \n  )  \n# Print the first few rows of the tibble  \nprint(standings_2014) \n\n# A tibble: 12 × 11\n       W     L   PCT GB    CONF  HOME  ROAD  STREAK `L-10` rank  team      \n   &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;     \n 1    29     5 0.853 --    19-3  16-1  13-4  W2     8-2    1     1PHOClose \n 2    19    15 0.559 --    11-11 13-4  6-11  L1     4-6    1     1ATLClose \n 3    16    18 0.471 --    12-10 7-10  9-8   L1     5-5    2     2INDClose \n 4    25     9 0.735 --    15-7  15-2  10-7  W1     7-3    2     2MINClose \n 5    16    18 0.471 --    9-13  8-9   8-9   W3     4-6    3     3LVAClose \n 6    16    18 0.471 --    11-11 8-9   8-9   L1     5-5    3     3WASClose \n 7    16    18 0.471 --    9-13  7-10  9-8   L1     6-4    4     4LASClose \n 8    15    19 0.441 --    14-8  9-8   6-11  L2     5-5    4     4CHIClose \n 9    15    19 0.441 --    10-12 10-7  5-12  W2     5-5    5     5NYLCircle\n10    12    22 0.353 --    7-15  8-9   4-13  L2     3-7    5     5SEACircle\n11    12    22 0.353 --    7-15  8-9   4-13  L3     4-6    6     6DALCircle\n12    13    21 0.382 --    8-14  9-8   4-13  W1     3-7    6     6CONCircle\n\n\n\nWrite a function whose only argument is year and scrapes the standings for that year. The year argument should be a column in the output data frame. (That is, the function result is a dataframe with columns: rank, team, W, L, … L-10, year. Remove the TEAM column after you’ve used it to create rank and team variables.) Print the first few row of the tibble.\n\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\n\n#  function to scrape the standings for a given year  \nscrape_standings &lt;- function(year) {  \n  standings &lt;- read_html(paste0(\"https://www.wnba.com/standings/?season=\", year)) |&gt;  \n   html_table() |&gt;  \n   pluck(1)  \n   \n  standings &lt;- standings |&gt;  \n   mutate(  \n    rank = str_extract(TEAM, \"^\\\\d+\"),  \n    team = str_remove(TEAM, \"^\\\\d+\\\\s\"),  \n    TEAM = NULL,  \n    year = year  \n   )  \n   \n  return(standings)  \n}  \n\n\nUse map() to scrape all the team data between 2010 and 2024. Print the first few row of the tibble.\n\n\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\n\nyears &lt;- 2010:2024  \nstandings_all &lt;- map(years, scrape_standings) |&gt;  \n  list_rbind()  \n  \n# Print the first few rows of the tibble  \nprint(standings_all)  \n\n# A tibble: 180 × 12\n       W     L   PCT GB    CONF  HOME  ROAD  STREAK `L-10` rank  team       year\n   &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;\n 1    22    12 0.647 --    13-9  13-4  9-8   W6     8-2    1     1WASClose  2010\n 2    28     6 0.824 --    20-2  17-0  11-6  W3     6-4    1     1SEAClose  2010\n 3    22    12 0.647 --    14-8  13-4  9-8   W1     9-1    2     2NYLClose  2010\n 4    15    19 0.441 --    13-9  9-8   6-11  L2     4-6    2     2PHOClose  2010\n 5    14    20 0.412 --    11-11 8-9   6-11  W2     5-5    3     3LVAClose  2010\n 6    21    13 0.618 --    13-9  12-5  9-8   L3     5-5    3     3INDClose  2010\n 7    13    21 0.382 --    10-12 8-9   5-12  L1     5-5    4     4LASClose  2010\n 8    19    15 0.559 --    10-12 10-7  9-8   L2     4-6    4     4ATLClose  2010\n 9    17    17 0.5   --    9-13  12-5  5-12  L1     4-6    5     5CONCirc…  2010\n10    13    21 0.382 --    8-14  7-10  6-11  W1     5-5    5     5MINCirc…  2010\n# ℹ 170 more rows\n\n\n\nUsing ggplot(), create a line plot with year on the x-axis and PCT on the y-axis. Color each line according to the team. Do you see any trends of the teams over time?\n\n\nlibrary(ggplot2)\n\nggplot(standings_all, aes(x = year, y = PCT, color = team)) +  \n  geom_line() +\n  labs(title = \"WNBA Team Performance Over Time\", x = \"Year\", y = \"Win Percentage\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nQ3 Best places\nGo to https://www.bestplaces.net and search for Claremont, California. The website is used for comparing cities to determine where you might want to work or live.\n\nUsing the SelectorGadget, extract the following pieces of information from the Claremont page:\n\nproperty crime (just the number which is on a scale of 0 to 100)\nminimum income required for a single person to live comfortably (as a number)\naverage monthly rent for a 2-bedroom apartment (as a number)\nthe “about” paragraph (the very first paragraph above “Location Details”)\n\n\nPrint the first few row of the tibble.\n\n# Load necessary libraries  \nlibrary(rvest)  \nlibrary(tibble)  \nlibrary(stringr)  \n  \n# Read the html page  \npage &lt;- read_html(\"https://www.bestplaces.net/city/california/claremont\")  \n  \n# Scrape the property crime rate  \ncrime_rate &lt;- page |&gt;  \n  html_elements(\".crime_rate\") |&gt;  \n  html_text() |&gt;  \n  str_extract(\"\\\\d+\") |&gt;  \n  as.numeric()  \n  \n# Scrape the minimum income required for a single person to live comfortably  \nmin_income &lt;- page |&gt;  \n  html_elements(\".min_income\") |&gt;  \n  html_text() |&gt;  \n  str_extract(\"\\\\d+\") |&gt;  \n  as.numeric()  \n  \n# Scrape the average monthly rent for a 2-bedroom apartment  \nrent_2br &lt;- page |&gt;  \n  html_elements(\".rent_2br\") |&gt;  \n  html_text() |&gt;  \n  str_extract(\"\\\\d+\") |&gt;  \n  as.numeric()  \n  \n# Scrape the \"about\" paragraph  \nabout &lt;- page |&gt;  \n  html_elements(\".about\") |&gt;  \n  html_text()  \n  \n# Put it all in a data frame  \nbest_places &lt;- tibble(  \n  state = \"California\",  \n  city = \"Claremont\",  \n  crime = crime_rate,  \n  min_income_single = min_income,  \n  rent_2br = rent_2br,  \n  about = about  \n)  \n  \n# Print the first few rows of the tibble  \nprint(best_places)  \n\n# A tibble: 0 × 6\n# ℹ 6 variables: state &lt;chr&gt;, city &lt;chr&gt;, crime &lt;dbl&gt;, min_income_single &lt;dbl&gt;,\n#   rent_2br &lt;dbl&gt;, about &lt;chr&gt;\n\n\n\nWrite a function called scrape_bestplaces() with arguments for city and state. When you run, for example scrape_bestplaces(\"california\", \"claremont\"), the output should be a 1x6 tibble with columns for state, city, crime, min_income_single, rent_2br, and about.\n\n\nscrape_bestplaces &lt;- function(state, city) {\n  page &lt;- read_html(paste0(\"https://www.bestplaces.net/city/\", state, \"/\", city))\n\n  crime &lt;- page |&gt;\n    html_element(\".crime-index .value\") |&gt;\n    html_text() |&gt;\n    as.numeric()\n\n  min_income &lt;- page |&gt;\n    html_element(\".income-index .value\") |&gt;\n    html_text() |&gt;\n    str_remove_all(\"[^0-9]\") |&gt;\n    as.numeric()\n\n  rent &lt;- page |&gt;\n    html_element(\".rent-index .value\") |&gt;\n    html_text() |&gt;\n    str_remove_all(\"[^0-9]\") |&gt;\n    as.numeric()\n\n  about &lt;- page |&gt;\n    html_element(\".about p\") |&gt;\n    html_text()\n\n  tibble(\n    state = state,\n    city = city,\n    crime = crime,\n    min_income_single = min_income,\n    rent_2br = rent,\n    about = about\n  )\n}\n\n\nUsing map2(), create a 5 x 6 tibble by running scrape_bestplaces() 5 times with 5 cities you are interested in. Be sure you look at the URL at bestplaces.net for the various cities to make sure it works as you expect. Print the first few row of the tibble.\n\nRunning the map2() function will look something like this:\n\nstates &lt;- c(\"california\", \"new-york\", \"texas\", \"florida\", \"oregon\")\ncities &lt;- c(\"claremont\", \"new-york-city\", \"austin\", \"miami\", \"portland\")\n\ncity_data &lt;- map2(states, cities, scrape_bestplaces) |&gt; \n  list_rbind()\n\nhead(city_data)\n\n# A tibble: 5 × 6\n  state      city          crime min_income_single rent_2br about\n  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;             &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;\n1 california claremont        NA                NA       NA &lt;NA&gt; \n2 new-york   new-york-city    NA                NA       NA &lt;NA&gt; \n3 texas      austin           NA                NA       NA &lt;NA&gt; \n4 florida    miami            NA                NA       NA &lt;NA&gt; \n5 oregon     portland         NA                NA       NA &lt;NA&gt; \n\n\n\n\nQ4 Permission\nCheck to make sure we are allowed to scrape data from the three websites: songkick, wnba, and bestplaces."
  },
  {
    "objectID": "project5.html",
    "href": "project5.html",
    "title": "project5",
    "section": "",
    "text": "title: “The Making of WAC Visualization” author: “Bernice Abanda” subtitle: “date of presentation” format: revealjs: scrollable: true slide-number: true show-slide-number: all embed-resources: true execute: echo: true warning: false message: false\n##My Favorite Project to Work on\nNetflix titles\n##What I liked about my Favorite Project\n##My Least Favorite Project to Work on\nUsing SQL to query the Wideband Acoustic Immittance (WAI) Database\n\n##What I Learned From my least Favorite Project\n##How I would approach both projects differently"
  }
]